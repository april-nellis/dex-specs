{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c57da73-cd92-4d5f-a656-984e5544a3f5",
   "metadata": {},
   "source": [
    "# Uniswap Decentralized Exchange Pool Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8743735f-7032-4784-aa11-17d2f777dd43",
   "metadata": {},
   "source": [
    "Owner: April Nellis\n",
    "\n",
    "Companion code to [*DEX Specs: A Mean-Field Approach to DeFi Cryptocurrency Exchanges*](https://arxiv.org/abs/2404.09090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685b196-f490-45ba-b045-3e605ae1d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import itertools\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import os.path\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import eth_abi\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy import optimize\n",
    "from IPython.display import Image\n",
    "from coinmetrics.api_client import CoinMetricsClient\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import import_ipynb\n",
    "from IPython.display import IFrame\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from decimal import Decimal\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "# Just disables the annoying warning, doesn't enable AVX/FMA\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "#plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams[\"figure.figsize\"] = [7,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204257e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Etherscan Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b02aa-b52c-4b75-a228-3dbf788991da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initializing pool information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef525e",
   "metadata": {},
   "source": [
    "Most analysis is performed on September 1-30, 2023 data. You may change the `start_date` and `end_date` variables to alter the blocks investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e57b428-8cb2-4d23-9928-b2d78a0e7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2023, 9, 1, 0, 0, 0) # year, month, day, hour, minute, second\n",
    "end_date = datetime(2023, 9, 30, 0, 0, 0)\n",
    "\n",
    "start_str = start_date.strftime('%Y-%m-%d')\n",
    "start_unix = int(time.mktime(start_date.timetuple()))\n",
    "\n",
    "end_str = end_date.strftime('%Y-%m-%d')\n",
    "end_unix = int(time.mktime(end_date.timetuple()))\n",
    "\n",
    "start_block = 18039179\n",
    "end_block = 18245998"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68a28a-b142-499c-9cef-6bade0dbf988",
   "metadata": {},
   "source": [
    "If you wish to change the dates, input the following API keys and run the code to find the correct start and end blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86053616-b02b-4488-9f3d-a1ffef060952",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '' # Input your personal Etherscan API key here (free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286a76c-8889-446b-bc9e-e47c19b68d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "GECKO_API = '' # Enter your personal CoinGecko API demo key here (free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a49aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = f'https://api.etherscan.io/api?module=block&action=getblocknobytime&timestamp={start_unix}&closest=before&apikey={API_KEY}'\n",
    "\n",
    "response = requests.get(my_url)\n",
    "resp = response.json()\n",
    "start_block = int(resp['result'])\n",
    "\n",
    "my_url = f'https://api.etherscan.io/api?module=block&action=getblocknobytime&timestamp={end_unix}&closest=before&apikey={API_KEY}'\n",
    "\n",
    "response = requests.get(my_url)\n",
    "resp = response.json()\n",
    "end_block = int(resp['result'])\n",
    "\n",
    "print(f'The period from {start_date} to {end_date} encompasses blocks {start_block} to {end_block} ({end_block-start_block} blocks).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276fc0ca",
   "metadata": {},
   "source": [
    "Coins of Interest:\n",
    "* **Ethereum (ETH)**\n",
    "    * This coin fluctuates in value compared to the US dollar. Native token of the Ethereum blockchain.\n",
    "* **(Wrapped) Bitcoin (WBTC)**\n",
    "    * The Bitcoin blockchain does not support smart contracts, which do most of the work of a decentralized exchange. Therefore, Bitcoin must be \"wrapped\" to be used in decentralized finance. This means that a token representing a Bitcoin is used in its place when placing transactions on other blockchains like the Ethereum blockchain.\n",
    "* **USD Coin (USDC)**\n",
    "    * This is a stablecoin with a value of 1 USD. It is supposed to be 1:1 collateralized with US dollars. \n",
    "* **Tether (USDT)**\n",
    "    * This is the most popular (as of Jan 2023) stablecoin, also having a value of 1 USD. It is supposed to be 1:1 collateralized with US dollars. \n",
    "* **Dai (DAI)**\n",
    "    * This is an algorithmic stablecoin which is also intended to have a value of 1 USD. It is overcollateralized using Ethereum via a series of smart contracts with the MakerDAO organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af29a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contract addresses for each coin:\n",
    "ETH = '0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2'\n",
    "WBTC = '0x2260FAC5E5542a773Aa44fBCfeDf7C193bc2C599'\n",
    "USDC = '0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48'\n",
    "USDT = '0xdAC17F958D2ee523a2206206994597C13D831ec7'\n",
    "DAI = '0x6B175474E89094C44Da98b954EedeAC495271d0F'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723a1642",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Choose pool of interest from below options. Uncomment and run the cell corresponding to your choice to choose the pool index.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34f499",
   "metadata": {},
   "source": [
    "[**DAI/USDC Pool with 0.05% Fee**](https://info.uniswap.org/#/pools/0x6c6bc977e13df9b0de53b251522280bb72383700) This pool allows exchanges of DAI and USDC. Activity in this pool has dropped off in favor of the DAI/USDC pool with a 0.01% fee, though both pools have more TVL and less trading volume than pairs with more volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e85d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POOL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c4344e",
   "metadata": {},
   "source": [
    "[**DAI/USDC Pool with 0.01% Fee**](https://info.uniswap.org/#/pools/0x5777d92f208679db4b9778590fa3cab3ac9e2168) This pool allows exchanges of DAI and USDC. Activity in this pool is frequent but trade sizes are relatively small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e18385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POOL = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2db66",
   "metadata": {},
   "source": [
    "[**USDC/ETH Pool with 0.05% Fee**](https://info.uniswap.org/#/pools/0x88e6a0c2ddd26feeb64f039a2c41296fcb3f5640): This pool facilitates swaps between USDC and Ethereum. This pool has the largest daily trading volume and a much higher TVL than other USDC/ETH pools (as of 01/24/2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa76a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the pool discussed in the paper\n",
    "POOL = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dacc4ae",
   "metadata": {},
   "source": [
    "[**USDC/ETH with 0.01% Fee**](https://info.uniswap.org/#/pools/0xe0554a476a092703abdb3ef35c80e0d76d32939f): This pool facilitates swaps between USDC and Ethereum. This pool did not have much activity until November 17-18, 2022, after which its use has been steading growing. The pool may not have existed before this time - further investigation necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POOL = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a70c5f1",
   "metadata": {},
   "source": [
    "[**USDC/USDT with 0.01% Fee**](https://info.uniswap.org/#/pools/0x3416cf6c708da44db2624d63ea0aaef7113527c6): This pool facilitates swaps between USDC and Tether. This stablecoin pair sees more activity than the USDC/DAI pairing, perhaps because Tether is preferred to DAI in certain cryptocurrency uses or because Tether is viewed as more reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POOL = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93261d3d",
   "metadata": {},
   "source": [
    "[**WTBC/ETH with 0.05% Fee**](https://info.uniswap.org/#/pools/0x4585fe77225b41b697c938b018e2ac67ac5a20c0): This pool facilitates swaps between wrapped Bitcoin and Ethereum. Note that the prices of both these token experience high volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477af168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POOL = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a16192",
   "metadata": {},
   "source": [
    "[**ETH/USDT with 0.05% Fee**](https://info.uniswap.org/#/pools/0x11b815efb8f581194ae79006d24e0d814b7697f6): This pool facilitates swaps between Ethereum and Tether. While USDC is still the preferred stablecoin to swap with Ethereum, this pool also has a decent amount of activity. However, trading volume appears to have decreased significantly since May 2022. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56136e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POOL = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670dc54",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Define the associated parameters.**\n",
    "\n",
    "`POOL` is the key, and the value is a tuple storing `(TOK_A, TOK_A_ADR, TOK_B, TOK_B_ADR, FEE, PROTOCOL_STR, PROTOCOL)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet = {1:('DAI', DAI, 'USDC', USDC, '005', 'Uniswap V3: DAI-USDC', '0x6c6bc977e13df9b0de53b251522280bb72383700'),\n",
    "         2:('DAI', DAI, 'USDC', USDC, '001', 'Uniswap V3: DAI-USDC 4', '0x5777d92f208679db4b9778590fa3cab3ac9e2168'),\n",
    "         3:('ETH', ETH, 'USDC', USDC,'005', 'Uniswap V3: USDC 3', '0x88e6a0c2ddd26feeb64f039a2c41296fcb3f5640'),\n",
    "         4:('ETH', ETH, 'USDC', USDC,  '001', 'Uniswap V3: USDC 4', '0xe0554a476a092703abdb3ef35c80e0d76d32939f'),\n",
    "         5:('USDC', USDC, 'USDT', USDT,'001','Uniswap V3: USDC-USDT 4','0x3416cf6c708da44db2624d63ea0aaef7113527c6'),\n",
    "         6:('WBTC', WBTC, 'ETH', ETH, '005', 'Uniswap V3: WBTC 2', '0x4585fe77225b41b697c938b018e2ac67ac5a20c0'),\n",
    "         7: ('ETH', ETH, 'USDT', USDT, '005', 'Uniswap V3: USDT 3', '0x11b815efb8f581194ae79006d24e0d814b7697f6')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbcea4",
   "metadata": {},
   "source": [
    "Load pool-specific information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(TOK_A, TOK_A_ADR, TOK_B, TOK_B_ADR, FEE, PROTOCOL_STR, PROTOCOL) = wallet[POOL]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac0063-a1e0-4efe-837c-59529fcfce9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Notable user information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b5ecf0-70de-4065-aead-c86eda6339b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying notable users\n",
    "weird_bot_1 = '0xa69babef1ca67a37ffaf7a485dfff3382056e78c' # Only does one half of transaction, always through Uniswap router\n",
    "weird_bot_2 = '0xe841e62778d997729cbbe165b029ebb4af8a58ab' # Paired with weird_bot_1, address not labeled as MEV but txn labeled as MEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55d987-3a16-4129-be9a-a4ddb75546f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NFT = '0xc36442b4a4522e871399cd717abdd847ab11fe88' # Uniswap V3: Positions NFT (tracks liquidity position)\n",
    "ROUTER = '0x68b3465833fb72a70ecdf485e0e4c7bd8665fc45|0xe592427a0aece92de3edee1f18e0157c05861564|0xef1c6e67703c7bd7107eed8303fbe6ec2554bf6b' # Uniswap V3: Router 2, facilitates exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b53d27-b469-49c1-b511-89f002f83381",
   "metadata": {},
   "outputs": [],
   "source": [
    "bots = []\n",
    "bots.append('0x57c1e0c2adf6eecdb135bcf9ec5f23b319be2c94')\n",
    "bots.append('0x00000000032962b51589768828ad878876299e14')\n",
    "bots.append('0xe8c060f8052e07423f71d445277c61ac5138a2e5')\n",
    "bots.append('0x83bc685ebd7e641f83f45cecdfe62b87afaef9c7') # Associated with 0xe8c06.. bot, same creator\n",
    "bots.append('0x00000000003b3cc22af3ae1eac0440bcee416b40')\n",
    "bots.append('0x493f461aead031cee2027f1b95370a692611acb9')\n",
    "bots.append('0x5050e08626c499411b5d0e0b5af0e83d3fd82edf')\n",
    "bots.append(weird_bot_1)\n",
    "bots.append('0xa57bd00134b2850b2a1c55860c9e9ea100fdd6cf')\n",
    "bots.append(weird_bot_2)\n",
    "bots.append('0x56178a0d5f301baf6cf3e1cd53d9863437345bf9')\n",
    "\n",
    "MEV = bots[0] #MEV bots, labeled by Etherscan - maximal extractable value\n",
    "for bot in bots[1:]:\n",
    "    MEV = MEV + '|' + bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2775bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bca6ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Function definitions\n",
    "ATTENTION! This section only needs to be run if you change the dates or the pool in the initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa695ca3",
   "metadata": {},
   "source": [
    "The function `get_dataframe` takes a token name string (`tok_name`), the corresponding token address (`tok_adr`), the address associated with the Uniswap protocol (`protocol`), and the starting and ending block numbers (`start` and `end`). Note the addresses are long strings. It returns a Pandas Dataframe containing the first 10,000 transactions within the given block range, involving the specified token and protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(tok_name, tok_adr, protocol, start, end):\n",
    "    start = int(start)\n",
    "    end = int(end)\n",
    "    \n",
    "    my_url = f\"https://api.etherscan.io/api?module=account&action=tokentx&contractaddress={tok_adr}&address={protocol}&startblock={start}&endblock={end}&sort=asc&apikey={API_KEY}\"\n",
    "    response = requests.get(my_url)\n",
    "    resp = response.json()\n",
    "    if int(resp['status']) == 1:\n",
    "        df = pd.DataFrame(resp['result'])\n",
    "        df['blockNumber'] = df['blockNumber'].astype(int)\n",
    "        df['value'] = df['value'].astype(float)/np.power(10, df['tokenDecimal'].astype(int))\n",
    "        df['gasPrice'] = df['gasPrice'].astype(float)/(1e18) # gas price given in ETH, adjusted by 18 decimal places\n",
    "        df['gasFee']=df['gasPrice']*(df['gasUsed'].astype(float))\n",
    "\n",
    "        df.rename(columns={'from':f'From{tok_name}', 'to':f'To{tok_name}','value':tok_name, 'hash':'Txnhash'}, inplace = True)\n",
    "        df.drop(['nonce', 'tokenName', 'tokenSymbol', 'transactionIndex', 'tokenDecimal', 'input', 'confirmations', 'gas', 'cumulativeGasUsed'], axis = 1, inplace = True)\n",
    "\n",
    "        if (df['contractAddress'] == tok_adr.lower()).all():\n",
    "            df.drop(['contractAddress'], axis = 1, inplace = True)\n",
    "        else:\n",
    "            print('Address mismatch?')\n",
    "    else:\n",
    "        df = pd.DataFrame(columns = ['blockNumber', 'timeStamp', 'Txnhash', 'blockHash', f'From{tok_name}', f'To{tok_name}', tok_name, 'gasPrice', 'gasUsed', 'gasFee'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343d89c-aa81-4675-980c-0b087b8a2c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function usage:\n",
    "temp = get_dataframe(TOK_A, TOK_A_ADR, PROTOCOL, start_block, start_block + 3)\n",
    "if temp.empty:\n",
    "    print('Empty')\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2bee5d-ffca-4404-bd27-097ee998277b",
   "metadata": {},
   "source": [
    "Get the logs and information for a specific transaction hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556cd3e0-5fc6-4155-abf6-86a5137dff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txn(txnhash):\n",
    "    txn_url=f'https://api.etherscan.io/api?module=proxy&action=eth_getTransactionReceipt&txhash={txnhash}&apikey={API_KEY}'\n",
    "    response = requests.get(txn_url)\n",
    "    resp = response.json()\n",
    "    from_usr = resp['result']['from']\n",
    "    to_usr = resp['result']['to']\n",
    "    \n",
    "    return (from_usr, to_usr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9760a9-1de9-4374-ba53-55a900a75654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function usage\n",
    "(a, b) = get_txn('0x11a6cfccf1f3684c68c6086be88ce16fce742fe8068f32bd9b976b33589c8968')\n",
    "print(f\"This transaction is from {a} to {b}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb5f91-7ad9-40d6-a374-02b123474a1f",
   "metadata": {},
   "source": [
    "Identify users who were obscured by the Uniswap router for both the incoming and outgoing transactions. If the master file is already saved as a CSV, this has already been taken care of. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59271e-95b0-491a-960b-fcde1abf75ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a long time if there is a long list of transactions because it requires a lot of API queries\n",
    "def replace_router(df):\n",
    "    a = df[f'User{TOK_A}'].str.contains(ROUTER)\n",
    "    b = df[f'User{TOK_B}'].str.contains(ROUTER)\n",
    "    txn_list = df['Txnhash'][a*b] # both users are the router (if only one, we already have some info)\n",
    "    print(f'There are {np.sum(a*b)} router transactions.')\n",
    "    \n",
    "    for idx in txn_list.index:\n",
    "        txn = df['Txnhash'][idx]\n",
    "        (from_usr, to_usr) = get_txn(txn)\n",
    "\n",
    "        if to_usr not in ROUTER:\n",
    "            print(f'Recipient is {to_usr} at index {idx}.')\n",
    "\n",
    "        if df[TOK_A].iloc[idx] > 0:\n",
    "            df[f'User{TOK_A}'].iloc[idx] = from_usr\n",
    "            df[f'User{TOK_B}'].iloc[idx] = to_usr\n",
    "        else:\n",
    "            df[f'User{TOK_B}'].iloc[idx] = from_usr\n",
    "            df[f'User{TOK_A}'].iloc[idx] = to_usr\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71d9a9-e5cc-425d-a348-7e65d3ba0805",
   "metadata": {},
   "source": [
    "Identify users who are obscured by the Positions NFT contract when withdrawing their liquidity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8419d0ef-08fe-4e26-8b33-c1b363316d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nft(df):\n",
    "    a = df[f'User{TOK_A}'].str.contains(NFT)\n",
    "    b = df[f'User{TOK_B}'].str.contains(NFT)\n",
    "    txn_list = df.index[a*b] # both users are the Positions NFT\n",
    "    print(f'There are {np.sum(a*b)} Positions NFT transactions.')\n",
    "    \n",
    "    for idx in txn_list:\n",
    "        txn = df['Txnhash'].loc[idx]\n",
    "        (from_usr, to_usr) = get_txn(txn)\n",
    "        #print(from_usr, to_usr)\n",
    "\n",
    "        if to_usr == NFT and from_usr == NFT:\n",
    "            print('ugh, no new info')\n",
    "        elif from_usr != NFT:\n",
    "            df[f'User{TOK_A}'].loc[idx] = from_usr # leave this one for now\n",
    "            #df[f'User{TOK_B}'].loc[idx] = from_usr \n",
    "        elif to_usr != NFT:\n",
    "            print(f'weird at {idx}')\n",
    "        else:\n",
    "            print(f'Extra user {to_usr} at {idx}.')\n",
    "            df[f'User{TOK_A}'].loc[idx] = from_usr\n",
    "            #df[f'User{TOK_B}'].loc[idx] = from_usr\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac48dccd-01a2-476d-8514-d4fffe0d325d",
   "metadata": {},
   "source": [
    "Since CoinMetrics hourly data is restricted to paid users and my free trial expired, we switch to CoinGecko, which has hourly data available for any date in the last 90 days. Granularity is automatic, so if the dates are more than 90 days in the past, daily data will be provided instead (alas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475b92a-a456-476c-93f6-c9cd4fe062b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gecko_prices(token):\n",
    "    if token == 'ETH':\n",
    "        coin_id = 'ethereum'\n",
    "    elif token == 'WBTC':\n",
    "        coin_id = 'bitcoin'\n",
    "    elif token == 'USDC':\n",
    "        coin_id = 'usd-coin'\n",
    "    elif token == 'USDT':\n",
    "        coin_id = 'tether'\n",
    "    elif token == 'DAI':\n",
    "        coin_id = 'dai'\n",
    "    else:\n",
    "        coin_id = ''\n",
    "        \n",
    "    url = f'https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart/range?vs_currency=usd&from={start_unix}&to={end_unix}&precision=full'\n",
    "    url_key = f'https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart/range?vs_currency=usd&from={start_unix}&to={end_unix}&precision=full&x_cg_demo_api_key={GECKO_API}'\n",
    "    response = requests.get(url)\n",
    "    resp = response.json()\n",
    "    if 'error' in resp.keys():\n",
    "        print(resp)\n",
    "    else:\n",
    "        price_df = pd.DataFrame(resp[\"prices\"])\n",
    "        price_df.rename(columns={0: \"time\", 1: \"price\"}, inplace = True)\n",
    "        price_df[\"time\"] = pd.to_datetime(price_df[\"time\"], unit='ms')\n",
    "        return price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f3b039-925c-4c2e-b477-225d057a66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gecko_prices(TOK_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cd2be7-7400-490f-a29a-008e4fa3e2f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Create the master DataFrame\n",
    "ATTENTION! This section only needs to be run if you change the dates or the pool in the initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f650d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Pull data from Etherscan if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKEN A\n",
    "fileStringA = f'data/pool{POOL}_{TOK_A}_{start_block}_{end_block}.csv'\n",
    "fileExistsA = os.path.isfile(fileStringA)\n",
    "\n",
    "if fileExistsA:\n",
    "    print('Loading CSV file...')\n",
    "    token_a = pd.read_csv(fileStringA)\n",
    "    token_a.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "    print('Done.')\n",
    "else:\n",
    "    print('Pulling data from Etherscan...')\n",
    "    token_a = get_dataframe(TOK_A, TOK_A_ADR, PROTOCOL, start_block, end_block)\n",
    "    start_block_temp = token_a['blockNumber'].iloc[-1]\n",
    "    \n",
    "    while start_block_temp < end_block:\n",
    "        # start from the next block with next 10000 transactions\n",
    "        print(f'Block {start_block_temp}')\n",
    "        temp = get_dataframe(TOK_A, TOK_A_ADR, PROTOCOL, start_block_temp, end_block)\n",
    "        \n",
    "        if temp.empty:\n",
    "            break\n",
    "        else:\n",
    "            token_a = pd.concat([token_a, temp], ignore_index = True)\n",
    "\n",
    "            start_block_temp = token_a['blockNumber'].iloc[-1]\n",
    "\n",
    "            # fill in the potential additional transactions in last block within batch of 10000 transactions\n",
    "            temp = get_dataframe(TOK_A, TOK_A_ADR, PROTOCOL, start_block_temp, start_block_temp)\n",
    "            token_a = pd.concat([token_a, temp], ignore_index = True)  \n",
    "            start_block_temp += 1\n",
    "\n",
    "            time.sleep(0.5) # just to ensure that the speed does not exceed the 5 request/second limit for a free account\n",
    "    \n",
    "    token_a.to_csv(fileStringA)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eef815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKEN B\n",
    "fileStringB = f'data/pool{POOL}_{TOK_B}_{start_block}_{end_block}.csv'\n",
    "fileExistsB = os.path.isfile(fileStringB)\n",
    "\n",
    "if fileExistsB:\n",
    "    print('Loading CSV file...')\n",
    "    token_b = pd.read_csv(fileStringB)\n",
    "    token_b.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "    print('Done.')\n",
    "else:\n",
    "    print('Pulling data from Etherscan...')\n",
    "    token_b = get_dataframe(TOK_B, TOK_B_ADR, PROTOCOL, start_block, end_block)\n",
    "    start_block_temp = token_b['blockNumber'].iloc[-1]\n",
    "    \n",
    "    while start_block_temp < end_block:\n",
    "        # start from the next block with next 10000 transactions\n",
    "        print(f'Block {start_block_temp}')\n",
    "        temp = get_dataframe(TOK_B, TOK_B_ADR, PROTOCOL, start_block_temp, end_block)\n",
    "        if temp.empty:\n",
    "            break\n",
    "        else:\n",
    "            token_b = pd.concat([token_b, temp], ignore_index = True)\n",
    "\n",
    "            start_block_temp = token_b['blockNumber'].iloc[-1]\n",
    "\n",
    "            # fill in the potential additional transactions in last block within batch of 10000 transactions\n",
    "            temp = get_dataframe(TOK_B, TOK_B_ADR, PROTOCOL, start_block_temp, start_block_temp)\n",
    "            token_b = pd.concat([token_b, temp], ignore_index = True)  \n",
    "            start_block_temp += 1\n",
    "             \n",
    "            time.sleep(0.5) # just to ensure that the speed does not exceed the 5 request/second limit for a free account\n",
    "            \n",
    "    token_b.to_csv(fileStringB)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defae185",
   "metadata": {
    "tags": []
   },
   "source": [
    "Clean data and merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84276354",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_a = token_a.drop_duplicates(subset='Txnhash', keep=False)\n",
    "new_b = token_b.drop_duplicates(subset='Txnhash', keep=False)\n",
    "\n",
    "if len(new_a) != len(new_b):\n",
    "    print(f'MISMATCH: there are {len(new_a)} {TOK_A} transactions and {len(new_b)} {TOK_B} transactions.')\n",
    "\n",
    "N = min(len(new_a), len(new_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46036ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine token A and token B transaction data based on transaction hashes\n",
    "master = new_a.merge(new_b, how = 'inner', on = 'Txnhash')\n",
    "if len(master) != N:\n",
    "    print(f'LOST INFORMATION: there are {len(master)} merged rows vs {N} original transactions.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66475271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up column names and improve readability\n",
    "for string in ['blockNumber', 'timeStamp', 'blockHash', 'gasFee', 'gasPrice','gasUsed']:\n",
    "    if (master[f'{string}_x'] == master[f'{string}_y']).all():\n",
    "        master.drop(f'{string}_y', axis = 1, inplace = True)\n",
    "        master.rename(columns={f'{string}_x':string}, inplace = True)\n",
    "    else:\n",
    "        print(string)\n",
    "        print(np.sum(master[f'{string}_x']== master[f'{string}_y']))\n",
    "\n",
    "master.drop('blockHash', axis = 1, inplace = True)\n",
    "master['timeStamp'] = pd.to_datetime(master['timeStamp'], unit = 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda68f4f-aa45-4fe1-bd36-bdd45c9cecbd",
   "metadata": {},
   "source": [
    "Calculate exchange rate without taking into acccount Uniswap transaction fee:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae0bd1-acfc-454a-aeb4-188e3996bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop very small transactions as they add weird things\n",
    "master = master[np.abs(master[TOK_B]) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213637f4-7980-43fb-a6fb-d924474392e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "master['Exchange Rate'] = np.abs(master[TOK_B])/master[TOK_A]\n",
    "master['Exchange Rate'].replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439714b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Categorize transactions as Add/Swap/Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine whether, for each transaction, money is entering or exiting Uniswap wallet \n",
    "\n",
    "a = -1*np.array(master[f'From{TOK_A}'].str.contains(PROTOCOL), dtype = 'int') # USDC leaving Uniswap\n",
    "b = np.array(master[f'To{TOK_A}'].str.contains(PROTOCOL), dtype = 'int') # USDC entering Uniswap\n",
    "uniswap_a = a+b # token A transactions from uniswap's perspective\n",
    "\n",
    "c = -1*np.array(master[f'From{TOK_B}'].str.contains(PROTOCOL), dtype = 'int') # DAI leaving Uniswap\n",
    "d = np.array(master[f'To{TOK_B}'].str.contains(PROTOCOL), dtype = 'int') #Dai entering Uniswap\n",
    "uniswap_b = c+d # token B transactions from uniswap's perspective\n",
    "\n",
    "# Check for txns where Uniwasp V3: TOK_A:TOK_B contract wallet not found\n",
    "if 0 in uniswap_a:\n",
    "    print(f\"Weird {TOK_A} transaction!\") \n",
    "if 0 in uniswap_b:\n",
    "    print(f'Weird {TOK_B} transaction!')\n",
    "\n",
    "# Create signed float transactions from Uniswap LP's viewpoint\n",
    "master[TOK_A] = master[TOK_A]*uniswap_a\n",
    "master[TOK_B] = master[TOK_B]*uniswap_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebdeb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename To/From as User, drop all instances of Uniswap wallet address to make my life easier\n",
    "for tok in [TOK_A, TOK_B]:\n",
    "    lista = master[f'From{tok}']\n",
    "    listb = master[f'To{tok}']\n",
    "    listbool = master[f'From{tok}'].str.contains(PROTOCOL)\n",
    "    master[f'User{tok}'] = [b if x else a for (x, a, b) in zip(listbool, lista, listb)]\n",
    "    master.drop([f'From{tok}', f'To{tok}'], axis = 1, inplace = True)\n",
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b24f3-e0de-412c-8d8d-1a32d67cf2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace router and nft with true end user if possible\n",
    "master = replace_router(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb29725-de71-43d5-bd02-e5d8e3e8b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "master = replace_nft(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d33f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns for my peace of mind\n",
    "new_order = [0,1,2,3,7,9,10,4,5,6,8]\n",
    "master = master[master.columns[new_order]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize transactions as Add/Swap/Remove\n",
    "txns = uniswap_a + uniswap_b\n",
    "if (1 in txns) or (-1 in txns):\n",
    "    print('ugh')\n",
    "\n",
    "master['Transaction Type'] = txns/2\n",
    "master['Transaction Label'] = master['Transaction Type'].map({-1: 'Remove', 0: 'Swap', 1:'Add'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de2dc8-387b-4b36-bcc2-98842f950752",
   "metadata": {},
   "source": [
    "Add Reference Rates (USD) from Coin Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc05b5f-eb43-484a-b9c3-990fa276aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pricesA = get_gecko_prices(TOK_A)\n",
    "pricesA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1fc462-6356-4d70-9c03-7d35b674bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pricesB = get_gecko_prices(TOK_B)\n",
    "pricesB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f38fe3-ff82-4e47-96ff-e7013a4028fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pricesA.copy()\n",
    "prices['price'] = np.array(pricesA['price'])/np.array(pricesB['price'])\n",
    "prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013a1333-0e9d-43ca-a172-b35b66ee099e",
   "metadata": {},
   "source": [
    "Format prices to add into master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede8c52-ac35-4366-975a-84f53fca58f7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_price = np.zeros(len(master))\n",
    "\n",
    "idx1 = 0\n",
    "idx2 = 0\n",
    "\n",
    "while idx1 < len(prices) and idx2 < len(market_price):\n",
    "    #print('hi')\n",
    "    ref = prices['time'].iloc[idx1]\n",
    "    tx = master['timeStamp'].iloc[idx2]\n",
    "    #print(ref)\n",
    "    #print(tx)\n",
    "    while ref.day >= tx.day and ref.hour > tx.hour:\n",
    "        idx2 += 1\n",
    "        tx = master['timeStamp'].iloc[idx2]\n",
    "    #print(idx2)\n",
    "    #print(tx)\n",
    "        \n",
    "    while ref.day == tx.day and ref.hour == tx.hour:\n",
    "        #print(prices['time'].iloc[idx1], master['timeStamp'].iloc[idx2])\n",
    "        market_price[idx2] = prices['price'].iloc[idx1]\n",
    "        idx2 += 1\n",
    "        if idx2 < len(market_price):\n",
    "            tx = master['timeStamp'].iloc[idx2]\n",
    "        else:\n",
    "            break\n",
    "    idx1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf30d70-f847-4bd2-ad88-22af942fd392",
   "metadata": {},
   "outputs": [],
   "source": [
    "master['Market Price'] = market_price\n",
    "master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f60b435-fb95-4b6f-9804-c12de91c02d4",
   "metadata": {},
   "source": [
    "Identify bot transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585fcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = master[f'User{TOK_A}'].str.contains(MEV)\n",
    "b = master[f'User{TOK_B}'].str.contains(MEV)\n",
    "master['botFlag'] = a+b\n",
    "print(f'There are {np.sum(a+b)} identified bot transactions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c54e3-d50e-437d-b280-35ceba4b38e4",
   "metadata": {},
   "source": [
    "Save the master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1eae1f-0d27-483c-9206-8681015195cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_string = f'data/pool{POOL}_master_{start_block}_{end_block}.csv'\n",
    "master.to_csv(master_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6fc7b9-7cee-405f-a367-2fb175694e26",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Or, load a pre-existing master CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a82ce2-2d58-4bf7-868c-6941d7e3e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_string = 'data/pool3_master_18039179_18245998.csv'\n",
    "# master_string = f'data/pool{POOL}_master_{start_block}_{end_block}.csv' # uncomment if loading a different CSV file\n",
    "master = pd.read_csv(master_string)\n",
    "master.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "master['timeStamp'] = pd.to_datetime(master['timeStamp'])\n",
    "master['Exchange Rate'].replace([np.inf, -np.inf], np.nan, inplace=True) # just in case\n",
    "master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e8755-57aa-4e64-86de-230c47b053f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31287423-56d7-4bca-ae9e-24f43b5c7a1e",
   "metadata": {},
   "source": [
    "We calculate the effective exchange rate for swap transactions done in the pool.\n",
    "- Negative exchange rate for swap means the user paid token A and got token B (negative flow of token B wrt Uniswap, so user gets tok B).\n",
    "- Positive exchange rate for swap means the user paid token B and got token A.\n",
    "- Infinite exchange rate is replaced by NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb089de-4403-4e65-88f0-93e9a969579b",
   "metadata": {},
   "source": [
    "Split dataframe based on type of transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d94b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swap = master[master['Transaction Type'] == 0]\n",
    "df_add = master[master['Transaction Type'] == 1] # To___ columns are irrelevant\n",
    "df_remove = master[master['Transaction Type'] == -1] # From___ columns are irrelevant\n",
    "print(f'There are {len(df_swap)} swaps, {len(df_add)} adds, and {len(df_remove)} removals.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df_swap[TOK_A][df_swap['botFlag'] == False])\n",
    "mu = np.mean(data)\n",
    "sig = np.std(data)\n",
    "print(f'The data has mean {mu} and std. dev. {sig}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381df31-ae71-4e67-b645-1f84a6408dd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Fundamental (Market) Exchange Rate Versus Pool Exchange Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c22ccdc-44b9-46bf-8e13-9592e4bc3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(df_swap['timeStamp'], np.abs(df_swap['Exchange Rate']), label = 'Pool Exchange Rate')\n",
    "plt.plot(df_swap['timeStamp'], df_swap['Market Price'], label = 'Market Exchange Rate')\n",
    "plt.legend()\n",
    "plt.title(f'Real Exchange Rate Dynamics, {TOK_A}/{TOK_B} Pool with {FEE}% Fee')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(f'{TOK_B} / {TOK_A}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe9cfb-f8e2-4ab8-a245-3cda3492dcea",
   "metadata": {},
   "source": [
    "Looking at things from another direction, how often did swappers in the pool get a better rate than the CoinMetrics estimated hourly Reference Rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb49af6-4690-4a9a-9fec-44bd448d554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exchange rate negative, smaller absolute value better\n",
    "pt1 = df_swap[df_swap['Exchange Rate'] < 0]\n",
    "pt2 = pt1[-pt1['Exchange Rate'] < pt1['Market Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25425f-ce17-4dfb-af60-d238dbd08a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exchange rate positive, bigger better\n",
    "pt3 = df_swap[df_swap['Exchange Rate'] > 0]\n",
    "pt4 = pt3[pt3['Exchange Rate'] > pt3['Market Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c12ae-aa40-4eed-8d6b-64d6b23aec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = pt2['Market Price'] + pt2['Exchange Rate']\n",
    "diff2 = pt4['Exchange Rate'] - pt4['Market Price']\n",
    "diff = np.concatenate([diff1, diff2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223e9cc-f651-4f9b-8cf8-c17877196914",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Out of {len(df_swap)} swap transactions, there were {len(pt2) + len(pt4)} with an exchange rate better than the estimated market reference rate.\")\n",
    "print(f\"This means {round((len(pt2) + len(pt4))/len(df_swap)*100, 2)}% were advantageous swaps with a max improvement of {round(np.amax(diff),4)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfd65fb-b2b4-483f-8c30-8255f8040418",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Gas Fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb54fbb-f346-4fdc-8a0b-171366c5b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.scatter(np.abs(df_swap[TOK_B]), df_swap['gasFee']*df_swap['Market Price'], alpha = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab85aa-3ba5-4896-b4d5-ef79d0ad5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average gas fee for swap\n",
    "np.mean(df_swap['gasFee']*df_swap['Market Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6e3e3-8919-4a39-8a66-6ecbecb22cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.scatter(np.abs(df_add[TOK_B]), df_add['gasFee']*df_add['Market Price'], alpha = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d695d-8e24-408c-8753-21cfeff79c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average gas fee for liquidity addition\n",
    "np.mean(df_add['gasFee']*df_add['Market Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698e0f6-3e9b-46f2-a13f-577573208b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.scatter(np.abs(df_remove[TOK_B]), df_remove['gasFee']*df_remove['Market Price'], alpha = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd51c13-ceac-4700-bac2-c45b34ef0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average gas fee for liquidity removal\n",
    "np.mean(df_remove['gasFee']*df_remove['Market Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144bf76a-dd89-40fa-b504-e7ba08f585df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Fitting Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd1455-40af-487e-984a-cffcb18a1b0b",
   "metadata": {},
   "source": [
    "We examine the distribution of swap arrival times to determine whether it would be better to model swaps as a continuous process (most swaps occur at equally spaced intervals) or as a Poisson point process (random amounts of time between arrivals, time between arrivals would follow exponential distribution). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd6b93-457a-4e63-9452-07b6b564d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swap.drop(columns=['Transaction Type', 'Transaction Label'], inplace = True)\n",
    "df_swap['Direction'] = np.sign(df_swap[TOK_B]) # +1 is swap USDC for TOK_A, -1 is swap TOK_A for USDC\n",
    "df_swap = df_swap[np.abs(df_swap[TOK_B]) > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d8c28-86ef-4a0f-a060-f7978f7f7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = (np.array(df_swap['timeStamp'].iloc[1:]) - np.array(df_swap['timeStamp'].iloc[:-1]))/np.timedelta64(1, 's')\n",
    "df_swap['time diff'] = np.concatenate([np.zeros(1), dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd674da-4b9d-4ed3-9609-cedeb06ee439",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.abs(np.array(df_swap['Exchange Rate'])) - np.array(df_swap['Market Price']) # p^* - m^*\n",
    "df_swap['price diff'] = diff#np.concatenate([np.zeros(1), diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f4ea6-4782-4aea-8820-2cada46cc635",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(df_swap['price diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f271d-aa8b-4a53-9cbe-d7ca79d2c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swap['price diff'] = np.maximum(df_swap['price diff'], -200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a0e0d-2cc3-4851-8237-6ca8740b93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_swap = df_swap[df_swap['botFlag'] == False]\n",
    "exo_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d328e15-e174-4134-8b76-d7614bc20050",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = []\n",
    "for i in range(len(exo_swap)-2):\n",
    "    if np.abs(exo_swap[TOK_B].iloc[i+2] + exo_swap[TOK_B].iloc[i]) < 50:\n",
    "        drop_list.append(i)\n",
    "        drop_list.append(i+2)\n",
    "exo_extreme = exo_swap.drop(index=exo_swap.index[drop_list])\n",
    "exo_extreme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b148a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predicting transaction arrival times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd8aab-09a6-4d84-8e17-a29365632df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_start = exo_swap['blockNumber'].iloc[0]\n",
    "block_end = exo_swap['blockNumber'].iloc[-1]\n",
    "tracker = np.zeros((block_end - block_start + 1, 2))\n",
    "\n",
    "blk_ctr = 0\n",
    "for i in range(len(exo_swap)):\n",
    "    while exo_swap['blockNumber'].iloc[i] > blk_ctr + block_start:\n",
    "        #print(f'Mismatch: {exo_swap[\"blockNumber\"].iloc[i]} vs {block_start + blk_ctr}')\n",
    "        tracker[blk_ctr,0] = -1\n",
    "        tracker[blk_ctr, 1] = exo_swap['price diff'].iloc[i]\n",
    "        blk_ctr += 1\n",
    "    if exo_swap['blockNumber'].iloc[i] == blk_ctr + block_start:\n",
    "        #print(f'{exo_swap[\"blockNumber\"].iloc[i]} matches with {block_start + blk_ctr}')\n",
    "        tracker[blk_ctr,0] = 1\n",
    "        tracker[blk_ctr, 1] = exo_swap['price diff'].iloc[i]\n",
    "        blk_ctr += 1\n",
    "    #elif exo_swap['blockNumber'].iloc[i] < blk_ctr + block_start:\n",
    "    #   print('repeated block in exo_swap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9620c49-ba58-46fa-912c-a4f4b8d5086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(np.abs(tracker[:, 1]), bins = 20)\n",
    "probs = np.zeros(len(hist))\n",
    "for i in range(len(hist)):\n",
    "    success_in_bin = np.sum((np.abs(tracker[:,1]) >= bins[i])*(np.abs(tracker[:,1]) < bins[i+1])*(tracker[:,0] == 1))\n",
    "    probs[i] = success_in_bin/hist[i] # how many blocks are in bin and had a swap\n",
    "    if probs[i] < 1e-2:\n",
    "        print(i)\n",
    "best_fit = np.polyfit(bins[:-1],probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212d316-e3ec-4016-9ed3-14526ee18521",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b = best_fit\n",
    "shift = -1 * math.log(1/b - 1)\n",
    "scale = m/(b**2) * np.exp(shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36a46f-f5dd-41c3-b771-781316961dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "x = np.arange(np.amin(np.abs(tracker[:, 1])), np.amax(np.abs(tracker[:,1])))\n",
    "y = 1/(1 + np.exp(-scale*x-shift))\n",
    "plt.bar(bins[:-1], 1, edgecolor = 'C0', color = '#ededed', width = 1.5)\n",
    "plt.bar(bins[:-1], probs, edgecolor = 'C0', width = 1.5)\n",
    "\n",
    "plt.plot(x, y, label = 'Sigmoid')\n",
    "plt.plot(x, np.poly1d(best_fit)(x), label = 'Linear')\n",
    "plt.xlabel(r'$|p^* - m^*|$')\n",
    "plt.ylabel('Probability of Swap Arrival')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5ca31-0ca7-4c43-9ff8-704e2d641933",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predicting transaction direction and magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ffe7c-48ad-4765-8f2e-e5a3beb37559",
   "metadata": {},
   "source": [
    "A positive swap direction means that the user deposited Token B and received Token A, while a negative swap direction means the user deposited Token A and received Token B.\n",
    "\n",
    "A positive $p^* - m^*$ value means that Token A is \"worth more\" in the pool, so users should want to deposit Token A in the pool and withdraw Token B (meaning a negative swap direction) while a negative $p^* - m^*$ means that Token A is cheaper in the pool, so users should want to exchange their Token B for Token A. \n",
    "\n",
    "**Note**: Swappers see the difference between the current market exchange rate and the pool rate after the previous transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcabd9b-8be8-40fb-8aa6-003696700f9e",
   "metadata": {},
   "source": [
    "Investigation of size of swap vs size of $p^* - m^*$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e9452-8ceb-43fa-a0d1-f4364fba9cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "offset = 1\n",
    "data_x = exo_extreme['price diff'].iloc[:-offset] #[np.abs(exo_extreme[TOK_B]) > 1e6] \n",
    "x_reg = np.linspace(np.amin(data_x), np.amax(data_x), 50)\n",
    "data_y = (np.sign(exo_extreme[TOK_B])*np.log(np.abs(exo_extreme[TOK_B]))).iloc[offset:] #exo_extreme[TOK_B].iloc[offset:] # [np.abs(exo_extreme[TOK_B]) > 1e6] #exo_extreme[TOK_B].iloc[offset:]\n",
    "fit_result = stats.linregress(data_x, data_y)\n",
    "m = fit_result[0]\n",
    "b = fit_result[1]\n",
    "print(f'p-value = {fit_result.pvalue} and R-value = {fit_result.rvalue}.') # p-test\n",
    "plt.scatter(data_x, data_y, label = 'Data', alpha = 0.1)\n",
    "plt.plot(x_reg, x_reg*m + b, color = 'red', label = f'y = {round(m, 2)}x + {round(b, 2)}')\n",
    "plt.xlabel(r'$p^*-m^*$')\n",
    "plt.ylabel(r'sgn$(\\xi)\\ \\log_{10}(|\\xi|)$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f05bee-2895-40f0-b7bc-9f9d964e6476",
   "metadata": {},
   "source": [
    "Now let us view the joint density of $p^*-m^*$ and signed $\\log(\\xi)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1b31a-2b81-445f-bced-9878fa6c6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f3bc2-1eb8-473f-a9fb-64395104259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_list = np.linspace(np.amin(data_x), np.amax(data_x), 100)\n",
    "usdc_list = np.linspace(np.amin(data_y), np.amax(data_y), 100)\n",
    "grid_x, grid_y = np.meshgrid(arb_list, usdc_list)\n",
    "points = np.vstack([grid_x.ravel(), grid_y.ravel()])\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8fd4ed-16a9-401d-b3f9-8c4f64b1acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.vstack((np.array(data_x), np.array(data_y)))\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac96112-4d33-4249-b5f7-6a53faf49eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvkernel0 = stats.gaussian_kde(input_data, bw_method = 0.4/input_data.std(ddof=1)) # A 2-D array with shape (# of dims, # of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c8918-d598-4bc9-8bab-0dae81910f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvdens0 = mvkernel0(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3e979-b381-4787-b414-27658e2c7f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "# Plot the 3D surface\n",
    "ax.plot_surface(grid_x, grid_y, mvdens0.reshape(grid_x.shape), edgecolor='black', lw=0.2, alpha=0.3)#rstride=8, cstride=8)\n",
    "\n",
    "# Plot projections of the contours for each dimension.  By choosing offsets\n",
    "# that match the appropriate axes limits, the projected contours will sit on\n",
    "# the 'walls' of the graph.\n",
    "#ax.contour(grid_x, grid_y, mvdens0.reshape(grid_x.shape), zdir='z', offset=0, cmap='coolwarm')\n",
    "ax.contour(grid_x, grid_y, mvdens0.reshape(grid_x.shape), zdir='x', offset=arb_list[0])#, cmap='coolwarm')\n",
    "ax.contour(grid_x, grid_y, mvdens0.reshape(grid_x.shape), zdir='y', offset=usdc_list[-1])#, cmap='coolwarm')\n",
    "\n",
    "ax.set(xlim=(arb_list[0], arb_list[-1]), ylim=(usdc_list[0], usdc_list[-1]), zlim=(0, 0.02), xlabel=r'$p^*-m^*$', ylabel=r'sgn$(\\xi)\\ \\log_{10}(|\\xi|)$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a6910-c170-4e8a-9b09-38426a48d5da",
   "metadata": {},
   "source": [
    "If you would like to see the conditional CDF for a given $p^*-m^*$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10291054-db44-46db-a184-654441713007",
   "metadata": {},
   "outputs": [],
   "source": [
    "points2 = np.zeros((2, len(usdc_list)))\n",
    "points2[0, :] = 4\n",
    "points2[1, :] =usdc_list\n",
    "cond_pdf= mvkernel0(points2)\n",
    "cond_cdf = np.cumsum(cond_pdf)\n",
    "cond_cdf = cond_cdf/cond_cdf[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f90cd7-24c3-45c5-9d62-ba371700fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.plot(usdc_list, cond_pdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e175884a-e476-41b8-a54c-fc1af370f51f",
   "metadata": {},
   "source": [
    "How do we simulate points from this distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e89214-ae01-4080-bb4b-f276316b304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_finder(x, domain, cdf):\n",
    "    i = np.searchsorted(cdf, x)\n",
    "    #print(i, cdf[i-1], cdf[i], domain[i-1], domain[i])\n",
    "    alpha = (x - cdf[i-1])/(cdf[i] - cdf[i-1])\n",
    "    #print(alpha)\n",
    "    sample = domain[i-1] + alpha*(domain[i]-domain[i-1])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e136d-4229-490c-969b-d3fc6b350a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_finder(0.45, usdc_list, cond_cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b773f1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Investigate MEV bot behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841b892-d266-4b76-b2f1-416d60300801",
   "metadata": {},
   "source": [
    "Let us make a preliminary pass at identifying bot attacks in the data. The method is as follows:\n",
    "1. Look at a transaction.\n",
    "2. \"Scan\" the next-next for another transaction from the same user or a known pair of bot attackers.\n",
    "3. If found, check whether the second transaction has the same size and opposite sign, within an error margin of 5%.\n",
    "4. If so, these two transactions constitute a bot attack! Consolidate the whole \"attack scheme\" into one row of attacks.\n",
    "5. Move on to the next transaction after the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d4f0a-8687-418e-ae17-c1c06f14d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = pd.DataFrame({'User':[], TOK_A:[], TOK_B:[], 'Profit':[], 'Perc. Profit':[], 'Start':[], 'End':[], 'Idx1':[], 'Idx2':[], 'Txn Scale': []})\n",
    "curr_df = master\n",
    "i = -1\n",
    "while i < len(curr_df)-3:\n",
    "    i += 1\n",
    "    user1 = [curr_df[f'User{TOK_A}'].iloc[i], curr_df[f'User{TOK_B}'].iloc[i]]\n",
    "    user2 = [curr_df[f'User{TOK_A}'].iloc[i+2], curr_df[f'User{TOK_B}'].iloc[i+2]]\n",
    "    \n",
    "    users = user1 + user2\n",
    "    user_overlap = list(set(user1) & set(user2))\n",
    "    matchFlag = False\n",
    "    \n",
    "    '''\n",
    "    # the user matching process is a little complicated because of certain bot \"paired\" behaviors observed in the data\n",
    "    if len(user_overlap) >=1:\n",
    "        user = user_overlap[0]\n",
    "        matchFlag = True\n",
    "    elif weird_bot_1 in users and weird_bot_2 in users: # weird bot combo matches\n",
    "        user = weird_bot_1\n",
    "        matchFlag = True\n",
    "    \n",
    "    '''\n",
    "    # ok here's the dumb way:\n",
    "    if user1[0] == user2[0] and user1[0] not in ROUTER: # first user matches\n",
    "        user = user1[0]\n",
    "        matchFlag = True\n",
    "    elif user1[1] == user2[1] and user1[1] not in ROUTER: # second user matches\n",
    "        user = user1[1]\n",
    "        matchFlag = True\n",
    "    elif weird_bot_1 in users and weird_bot_2 in users: # weird bot combo matches\n",
    "        user = weird_bot_1\n",
    "        matchFlag = True\n",
    "\n",
    "    idx1 = curr_df.index[i]\n",
    "    idx2 = curr_df.index[i+2]\n",
    "    \n",
    "    start = curr_df['timeStamp'].iloc[i]\n",
    "    end = curr_df['timeStamp'].iloc[i+2]\n",
    "\n",
    "    # if indices are close enough and users match, check transaction sizes\n",
    "    if (idx2 - idx1 == 2) and (matchFlag == True) and ((end - start)//np.timedelta64(1, 's') == 0):\n",
    "        pi_a = curr_df[TOK_A].iloc[i+2] + curr_df[TOK_A].iloc[i]\n",
    "        pi_b = curr_df[TOK_B].iloc[i+2] + curr_df[TOK_B].iloc[i]\n",
    "        scale = np.abs(curr_df[TOK_B].iloc[i]) # just the general size of the transaction\n",
    "\n",
    "        err_a = np.abs(pi_a)/max(np.abs(curr_df[TOK_A].iloc[i]), 1e-4)\n",
    "        err_b = np.abs(pi_b)/max(np.abs(curr_df[TOK_B].iloc[i]), 1e-4)\n",
    "        \n",
    "        flag1 = (curr_df['Transaction Type'].iloc[i] == 0) and (curr_df['Transaction Type'].iloc[i+2] == 0)\n",
    "        flag2 = (curr_df['Transaction Type'].iloc[i] == 1) and (curr_df['Transaction Type'].iloc[i+2] == -1)\n",
    "\n",
    "        if (flag1 or flag2) and (min(err_a, err_b) < 0.05):\n",
    "            botflag = (user in MEV)\n",
    "            \n",
    "            if curr_df['Transaction Type'].iloc[i] != 0:\n",
    "                attackType = 1 # liquidity-based attack\n",
    "            else:\n",
    "                attackType = 0 # swap-based attack\n",
    "\n",
    "            gas = curr_df['gasFee'].iloc[i] + curr_df['gasFee'].iloc[i+2]\n",
    "\n",
    "            curr_profit = -(pi_a*curr_df['Market Price'].iloc[i] + pi_b) - gas # recall that a negative transaction is going away from Uniswap, aka TO the user\n",
    "            rel = curr_profit/scale\n",
    "\n",
    "            attacks = attacks.append({'User':user, TOK_A:-pi_a, TOK_B:-pi_b, 'Profit':curr_profit, 'Perc. Profit': rel, 'Idx1':idx1, 'Idx2':idx2, 'Start':start, 'End':end, 'Txn Scale': scale, 'botFlag': botflag, 'Type': attackType}, ignore_index = True)\n",
    "\n",
    "print(len(attacks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a80c4-638b-4dde-a636-6068fed2ea5a",
   "metadata": {},
   "source": [
    "What percentage of bot attacks are swap sandwich attacks vs Just-in-Time (JIT) liquidity attacks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e0f86-4dc1-4b26-a41f-01f5f92a7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_attacks = np.sum(attacks['Type'] == 1)\n",
    "swap_attacks = np.sum(attacks['Type'] == 0)\n",
    "if liq_attacks + swap_attacks != len(attacks):\n",
    "    print('Issue')\n",
    "else:\n",
    "    print(f'Liquidity attacks were {round(liq_attacks/len(attacks), 4)*100}% of total.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c1be58-fe73-48ca-9e47-97c0e0d202cd",
   "metadata": {},
   "source": [
    "What percentage of identified bot attacks are done by our identified MEV bots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e20ab-62de-4cfb-9100-54416d1cfc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(attacks['botFlag'] == 1)/len(attacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07b862-0cad-474c-82e2-4dbc1e5663c8",
   "metadata": {},
   "source": [
    "To determine the value of $\\zeta$, we must answer: what percentage of vulnerable transactions does the Bot attack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ec80f-2bfc-4a18-8537-32871ec26509",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_threshold = 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca8fa2-559a-457d-8459-d912d2468be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = len(attacks) # number of bot attacks\n",
    "\n",
    "# number of vulnerable transactions\n",
    "n2 = 0\n",
    "for i in range(len(df_swap)):\n",
    "    big_enough = np.abs(df_swap[TOK_B].iloc[i]) > large_threshold\n",
    "    right_direction = ((np.abs(df_swap['Exchange Rate'].iloc[i]) - df_swap['Market Price'].iloc[0])*np.sign(df_swap[TOK_B].iloc[0]) > 0)\n",
    "    not_bot = ~df_swap['botFlag'].iloc[0]\n",
    "    if big_enough and right_direction and not_bot:\n",
    "        n2 += 1\n",
    "\n",
    "print(f'The bot attack rate, zeta, is {round(n1/n2 * 100, 3)}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54804ac1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Looking at LP Behavior in the Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93dedf2-b4d5-447f-886d-6a3b587a5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liq = master[master['Transaction Type'] != 0]\n",
    "df_liq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15e75e-583b-46f3-ab55-5c268af609e3",
   "metadata": {},
   "source": [
    "First, here is some code to visualize swaps and liquidity magnitude and direction for a small chunk of transactions at whichever index I choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3f14d-4356-4ab3-b8de-a51b0c690347",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 50\n",
    "chunk = master.iloc[i:i+15]\n",
    "\n",
    "tracker = 1\n",
    "for idx in range(1, len(chunk)):\n",
    "    if chunk['blockNumber'].iloc[idx] == chunk['blockNumber'].iloc[idx - tracker]:\n",
    "        chunk['blockNumber'].iloc[idx] += tracker/10\n",
    "        tracker +=1\n",
    "        \n",
    "    else:\n",
    "        tracker = 1\n",
    "\n",
    "df_bot = chunk[chunk['botFlag'] == True]\n",
    "not_bot = chunk[chunk['botFlag'] == False]\n",
    "\n",
    "swap_bot = df_bot[df_bot['Transaction Type'] == 0]\n",
    "swap_not = not_bot[not_bot['Transaction Type'] == 0]\n",
    "\n",
    "lp_bot = df_bot[df_bot['Transaction Type'] != 0]\n",
    "lp_not = not_bot[not_bot['Transaction Type'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02374b8a-7a9c-453c-b3ad-ec9ac17f3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "plt.yscale('symlog')\n",
    "\n",
    "plt.stem(swap_not['blockNumber'], swap_not[TOK_A], linefmt = 'g', markerfmt = \"gx\", label = 'Swap, People')\n",
    "plt.stem(lp_bot['blockNumber'], lp_bot[TOK_A], linefmt = 'r', markerfmt = \"rx\", label = 'Liquidity, Bots')\n",
    "plt.stem(lp_not['blockNumber'], lp_not[TOK_A], linefmt = 'b', markerfmt = \"bx\", label = 'Liquidity, People')\n",
    "plt.title(f'DEX Transactions')\n",
    "plt.legend()#bbox_to_anchor=(1.05, 0.55))\n",
    "plt.xlabel('Block Number')\n",
    "plt.ylabel('Value (USDC)')\n",
    "plt.axhline(0, color = 'black')\n",
    "ax = plt.gca()\n",
    "ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50937db4-1212-48fd-a2ab-c0193fc13201",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "\n",
    "axs[0].set_yscale('symlog')\n",
    "axs[1].set_yscale('symlog')\n",
    "\n",
    "#axs[0].stem(swap_bot['timeStamp'], swap_bot[TOK_A], linefmt = 'k', markerfmt = \"kx\", label = 'Swap, Bots')\n",
    "axs[0].stem(swap_not['blockNumber'], swap_not[TOK_A], linefmt = 'g', markerfmt = \"gx\", label = 'Swap, People')\n",
    "axs[0].stem(lp_bot['blockNumber'], lp_bot[TOK_A], linefmt = 'r', markerfmt = \"rx\", label = 'Liquidity, Bots')\n",
    "axs[0].stem(lp_not['blockNumber'], lp_not[TOK_A], linefmt = 'b', markerfmt = \"bx\", label = 'Liquidity, People')\n",
    "axs[0].set_title(f'{TOK_A} Transactions')\n",
    "axs[0].legend(bbox_to_anchor=(1.05, 0.55))\n",
    "\n",
    "axs[1].stem(swap_bot.index, swap_bot[TOK_B], linefmt = 'k', markerfmt = \"kx\", label = 'Swap, Bots')\n",
    "axs[1].stem(swap_not.index, swap_not[TOK_B], linefmt = 'g', markerfmt = \"gx\", label = 'Swap, People')\n",
    "axs[1].stem(lp_bot.index, lp_bot[TOK_B], linefmt = 'r', markerfmt = \"rx\", label = 'Liquidity, Bots')\n",
    "axs[1].stem(lp_not.index, lp_not[TOK_B], linefmt = 'b', markerfmt = \"bx\", label = 'Liquidity, People')\n",
    "axs[1].set_title(f'{TOK_B} Transactions')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e3101a-c9ce-4223-979f-332d685ac5b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Value of Liquidity Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c4755-666b-465c-b6e1-79a2aabff017",
   "metadata": {},
   "outputs": [],
   "source": [
    "lps = df_liq[df_liq['botFlag'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649f0589-2fe8-455e-b48a-6e45d6709e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1f7d7-3f6f-49ce-80f2-2a978c6ee4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = np.log10(np.array(np.abs(lps['USDC']) + np.abs(lps['ETH'])*np.array(lps['Market Price'])))\n",
    "value = value[value > 1]\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.25).fit(value[:, np.newaxis])\n",
    "s = np.linspace(0, np.amax(value), 100)\n",
    "e = np.exp(kde.score_samples(s.reshape(-1,1)))\n",
    "\n",
    "mi, ma = argrelextrema(e, np.less)[0], argrelextrema(e, np.greater)[0]\n",
    "print(\"Minima:\", s[mi], mi)\n",
    "print(\"Maxima:\", s[ma], ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67aba0b-8bf8-4b50-b861-75badd9fb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "plt.fill_between(s[:mi[0]+1], 0, e[:mi[0]+1], color='C0')\n",
    "for i in range(len(mi)-1):\n",
    "    plt.fill_between(s[mi[i]:mi[i+1]+1], 0, e[mi[i]:mi[i+1]+1], color=f'C{i+1}')\n",
    "    plt.vlines(s[mi[i]], 0, e[mi[i]], color = 'white')\n",
    "plt.vlines(s[mi[-1]], 0, e[mi[-1]], color = 'white')\n",
    "plt.fill_between(s[mi[-1]:], 0, e[mi[-1]:], color=f'C{len(mi)}')\n",
    "\n",
    "plt.scatter(s[ma], e[ma], color = 'black')\n",
    "\n",
    "plt.xlabel('Log Liquidity Contribution')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27483f-dbad-4690-84fb-ca2ee13458e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_list = 10**s[ma]\n",
    "capital_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d170b0-a6d8-4743-9299-8486057050b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.trapz(e, s)\n",
    "small = np.trapz(e[:mi[0]], s[:mi[0]])\n",
    "mid = np.trapz(e[mi[0]:mi[1]], s[mi[0]:mi[1]])\n",
    "large = np.trapz(e[mi[1]:], s[mi[1]:])\n",
    "probs = np.array([small, mid, large])/total\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b116392-8344-4a34-90d9-75a51a8c9c51",
   "metadata": {},
   "source": [
    "Let's check the estimated density vs the actual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46ac122-e27b-4f88-a040-e26fb47386d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(value[(value >= s[mi[0]])*(value < s[mi[1]])])/len(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15be84-2b22-4738-be56-87b547216b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(value[value < s[mi[0]]])/len(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb78af-58ba-4eee-9b0a-7deb1236e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(value[value > s[mi[1]]])/len(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c8176-d5aa-4cd4-8f46-8e5252f86abd",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### How long do LPs leave money in pool?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889d390-cfc2-431c-aabc-c9d33ef565b9",
   "metadata": {},
   "source": [
    "Identify additions and removals done by the same address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c92c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Match transactions in df_add and df_remove that came from the same user account\n",
    "user_list_add = list(df_add[f'User{TOK_A}'])\n",
    "user_list_add = user_list_add + list(df_add[f'User{TOK_B}'])\n",
    "lp_add = [*set(user_list_add)]\n",
    "\n",
    "user_list_rem = list(df_remove[f'User{TOK_A}'])\n",
    "user_list_rem = user_list_rem + list(df_remove[f'User{TOK_B}'])\n",
    "lp_rem = [*set(user_list_rem)]\n",
    "\n",
    "print(len(lp_add))\n",
    "print(len(lp_rem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b306d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "common = list(set(user_list_add).intersection(user_list_rem))\n",
    "print(len(common)) # common usernames between two lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da122152",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_out = pd.DataFrame(common)\n",
    "in_out.rename(columns={0:'User'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dates = []\n",
    "rem_dates = []\n",
    "for user in common:\n",
    "    add_dates.append(np.array(df_add.index[df_add[f'User{TOK_A}'].str.contains(user) + df_add[f'User{TOK_B}'].str.contains(user)]))\n",
    "    rem_dates.append(np.array(df_remove.index[df_remove[f'User{TOK_A}'].str.contains(user)+ df_remove[f'User{TOK_B}'].str.contains(user)]))\n",
    "in_out['Add Idx'] = add_dates\n",
    "in_out['Remove Idx'] = rem_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59fc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = pd.DataFrame(columns=['user', 'add_idx', 'remove_idx', 'Value', 'Profit', 'Time'])\n",
    "for i in range(len(common)):\n",
    "    liq = []\n",
    "    for idx in in_out['Add Idx'][i]:\n",
    "        for j in in_out['Remove Idx'][i]:\n",
    "            if j > idx:\n",
    "                start_a = df_add[TOK_A][idx]\n",
    "                start_b = df_add[TOK_B][idx]\n",
    "                add_date = df_add['timeStamp'][idx]\n",
    "                \n",
    "                end_a = -df_remove[TOK_A][j]\n",
    "                end_b = -df_remove[TOK_B][j]\n",
    "                rem_date = df_remove['timeStamp'][j]\n",
    "                \n",
    "                dA = (end_a - start_a)\n",
    "                dB = (end_b - start_b)\n",
    "                \n",
    "                val = end_a + end_b * df_remove['Market Price'][j]\n",
    "                pi = dA + dB * df_remove['Market Price'][j]\n",
    "                \n",
    "                df2 = {'user': in_out['User'][i], 'add_idx':idx, 'remove_idx':j, 'Value':val , 'Profit': pi, 'Time':(rem_date - add_date)/np.timedelta64(1, 's')}\n",
    "                positions = positions.append(df2, ignore_index = True)\n",
    "                break\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721df8e-686c-4410-9b3f-aea59859595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average time that liquidity is left in pool before adjustment\n",
    "np.mean(positions['Time'])/3600 # units are hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55059d5-2c52-42f0-9e40-62e728d02e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude JIT liquidity adjustments\n",
    "np.mean(positions['Time'][positions['Time'] > 0])/3600 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ded2b2-8795-4ca5-92d1-7e446721b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.scatter(positions['Value'], positions['Time']/3600)\n",
    "plt.xlabel('Value of Liquidity Position Upon Removal')\n",
    "plt.ylabel('Length of Time in Pool (hrs)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96d3e1f-88cd-4a4d-ac5d-b9e90404d7f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Position Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53156868-498e-4418-908d-2c63f60dd581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tick_to_price(tick, dec_a, dec_b):\n",
    "    # dec_a is the decimals for token a, dec_b is the decimals for token b numbers are stored by shifting decimal point to reduce rounding errors)\n",
    "    pt1 = 1.0001 ** tick\n",
    "    pt2 = pt1 * (10 ** (dec_b - dec_a)) # this gives prices as tokA/tokB\n",
    "    pt3 = 1/pt2 # we usually want tokB/tokA i.e. USDC/ETH for Market Price\n",
    "    \n",
    "    return pt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b44f21-c88d-407b-b708-407c27872573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position(contract, start_block, end_block):\n",
    "    df = pd.DataFrame(columns=['Txnhash', 'Owner', 'amount0', 'amount1', 'Position', 'Width'])\n",
    "    \n",
    "    mint_topic = '0x7a53080ba414158be7ec69b987b5fb7d07dee101fe85488f0853ae16239d0bde'\n",
    "    url1=f'https://api.etherscan.io/api?module=logs&action=getLogs&address={contract}&fromBlock={start_block}&toBlock={end_block}&topic0={mint_topic}&page=1&offset=1000&apikey={API_KEY}'\n",
    "    response = requests.get(url1)\n",
    "    resp = response.json()\n",
    "    \n",
    "    n_txn = len(resp['result'])\n",
    "    print(n_txn)\n",
    "    \n",
    "    for i in range(n_txn):\n",
    "        # parse JSON and remove 0x in front of hex values\n",
    "        accountHex = resp['result'][i]['topics'][1][2:]\n",
    "        lowerHex = resp['result'][i]['topics'][2][2:]\n",
    "        upperHex = resp['result'][i]['topics'][3][2:]\n",
    "        data = resp['result'][i]['data'][2:]\n",
    "\n",
    "        # convert from ABI to readable numbers\n",
    "        owner = eth_abi.decode(['address'], bytes.fromhex(accountHex), strict = False)[0]\n",
    "        lowerTick = eth_abi.decode(['int24'], bytes.fromhex(lowerHex), strict = False)[0]\n",
    "        upperTick = eth_abi.decode(['int24'], bytes.fromhex(upperHex), strict = False)[0]\n",
    "        sender, amount, amount0, amount1 = eth_abi.decode(['address', 'uint128', 'uint256', 'uint256'], bytes.fromhex(data), strict = False)\n",
    "\n",
    "        amount0 = amount0 * 1e-6 # USDC off by 10^{-6}\n",
    "        amount1 = amount1 * 1e-18 # ETH off by 10^{-18}\n",
    "        \n",
    "        df2 = {'Txnhash': resp['result'][i]['transactionHash'], 'Owner': owner, 'amount0': amount0, 'amount1': amount1, 'Position': np.array([lowerTick, upperTick]), 'Width': (upperTick - lowerTick)}\n",
    "        df = df.append(df2, ignore_index = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094c379-1ac1-469e-8e7d-c8718a6fde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_df = get_position(PROTOCOL, start_block, end_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547ad42b-f6d5-4fc2-ae17-526aabbd0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokA_price = np.mean(master['Market Price']) # could be more accurate\n",
    "liq_df['Value'] = np.array(liq_df['amount0']) + np.array(liq_df['amount1']) * tokA_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33428e0a-4ece-468b-ab50-9e236c8b1a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this bot makes many many transactions\n",
    "bigMEV = weird_bot_1\n",
    "bot_liq = liq_df[liq_df['Owner'] == bigMEV]\n",
    "print(np.mean(bot_liq['Width']))\n",
    "print(len(bot_liq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b23417-caed-4dac-90d2-6633bcc14dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tick = 887270\n",
    "min_tick = -887270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a835df-7f33-4229-aecb-8401dbc93a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_list = np.sort(np.vstack(liq_df['Position']).flatten())[13:-13] # get rid of extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5b79e-2981-4dee-96f5-c36ff7c369c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_liq = liq_df[(liq_df['Owner'] != bigMEV)*(liq_df['Width'] < (max_tick - min_tick))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b133b1-c563-4862-9019-a79ad80d40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.scatter(normal_liq['Value'], np.array(normal_liq['Width'], dtype = int))\n",
    "plt.xlabel('Position Value')\n",
    "plt.ylabel('Position Width')\n",
    "#plt.plot(np.arange(1, 5e6, 10), 5e4/np.arange(1, 5e6, 10) + 10, color = 'black')\n",
    "#plt.plot(np.arange(1, 5e6, 10), 1e5/np.exp(np.arange(1, 5e6, 10)) + 10, color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a45fa6-d136-4906-853b-cf85db4d4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_LP_fee, pi_LP_liq, pi_B = bot.calcProfit(x_1, x_2, xi, nu)\n",
    "pi_LP_fee, pi_LP_liq, pi_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b68bbe8-993d-4849-94af-919d32181b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Pool ER is {nu.pool_er} and Market ER is {nu.mkt_er}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af45323-fd41-4ff6-9b22-9c8f6523f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax = plt.subplots(2)\n",
    "space = nu.size//20\n",
    "\n",
    "ax[0].bar(np.arange(nu.size), nu.tokA, align = 'edge', tick_label = nu.ticks[1:], width = -1)\n",
    "#ax[0].axvline(nu.idx, color = 'red')\n",
    "ax[0].set_xticks(np.arange(-1, nu.size, space))\n",
    "ax[0].set_xticklabels(np.round(nu.ticks[0::space],2), rotation = 45, ha = 'right')\n",
    "\n",
    "ax[0].set_title(f'Token A Liquidity After Actual Swap')\n",
    "ax[0].set_xlabel('Exchange Rate')\n",
    "ax[0].set_ylabel('Quantity')\n",
    "\n",
    "ax[1].bar(np.arange(nu.size), nu.tokB, align = 'edge', tick_label = nu.ticks[1:], width = -1)\n",
    "#ax[1].axvline(nu.idx, color = 'red')\n",
    "ax[1].set_xticks(np.arange(-1, nu.size, space))\n",
    "ax[1].set_xticklabels(np.round(nu.ticks[0::space],2), rotation = 45, ha = 'right')\n",
    "\n",
    "ax[1].set_title(f'Token B Liquidity After Actual Swap')\n",
    "ax[1].set_xlabel('Exchange Rate')\n",
    "ax[1].set_ylabel('Quantity')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
